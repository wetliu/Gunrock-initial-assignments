/*
 * Copyright 1993-2007 NVIDIA Corporation.  All rights reserved.
 *
 * NOTICE TO USER:
 *
 * This source code is subject to NVIDIA ownership rights under U.S. and
 * international Copyright laws.  Users and possessors of this source code
 * are hereby granted a nonexclusive, royalty-free license to use this code
 * in individual and commercial software.
 *
 * NVIDIA MAKES NO REPRESENTATION ABOUT THE SUITABILITY OF THIS SOURCE
 * CODE FOR ANY PURPOSE.  IT IS PROVIDED "AS IS" WITHOUT EXPRESS OR
 * IMPLIED WARRANTY OF ANY KIND.  NVIDIA DISCLAIMS ALL WARRANTIES WITH
 * REGARD TO THIS SOURCE CODE, INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY, NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY SPECIAL, INDIRECT, INCIDENTAL,
 * OR CONSEQUENTIAL DAMAGES, OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS
 * OF USE, DATA OR PROFITS,  WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE
 * OR OTHER TORTIOUS ACTION,  ARISING OUT OF OR IN CONNECTION WITH THE USE
 * OR PERFORMANCE OF THIS SOURCE CODE.
 *
 * U.S. Government End Users.   This source code is a "commercial item" as
 * that term is defined at  48 C.F.R. 2.101 (OCT 1995), consisting  of
 * "commercial computer  software"  and "commercial computer software
 * documentation" as such terms are  used in 48 C.F.R. 12.212 (SEPT 1995)
 * and is provided to the U.S. Government only as a commercial end item.
 * Consistent with 48 C.F.R.12.212 and 48 C.F.R. 227.7202-1 through
 * 227.7202-4 (JUNE 1995), all U.S. Government End Users acquire the
 * source code with only those rights set forth herein.
 *
 * Any use of this source code in individual and commercial software must
 * include, in the user documentation and internal comments to the code,
 * the above Disclaimer and U.S. Government End Users Notice.
 */

/* Template project which demonstrates the basics on how to setup a project
* example application.
* Host code.
*/

// includes, system
#include <stdlib.h>
#include <stdio.h>
#include <string.h>
#include <math.h>

// includes, project
#include <cuda.h>
#define CUDA_SAFE_CALL_NO_SYNC( call) do {                              \
  cudaError err = call;                                                 \
  if( cudaSuccess != err) {                                             \
    fprintf(stderr, "Cuda error in file '%s' in line %i : %s.\n",       \
                __FILE__, __LINE__, cudaGetErrorString( err) );         \
    exit(EXIT_FAILURE);                                                 \
    } } while (0)

#define CUDA_SAFE_CALL( call) do {                                      \
  CUDA_SAFE_CALL_NO_SYNC(call);                                         \
  cudaError err = cudaThreadSynchronize();                              \
  if( cudaSuccess != err) {                                             \
     fprintf(stderr, "Cuda error in file '%s' in line %i : %s.\n",      \
                 __FILE__, __LINE__, cudaGetErrorString( err) );        \
     exit(EXIT_FAILURE);                                                \
     } } while (0)

// includes, kernels
//#include <test1_kernel.cu>
#define iterations 10000
//#define 
////////////////////////////////////////////////////////////////////////////////
//! Simple test kernel template for flops test
//! @param g_idata  input data in global memory
//! @param g_odata  output data in global memory
////////////////////////////////////////////////////////////////////////////////
__global__ void
testKernel( float* g_idata, float* g_odata, long int n)
{
    float result = 1.0f;
    int index = blockIdx.x*blockDim.x + threadIdx.x;
    float val1 = g_idata[index];
    float val2 = g_idata[index];
    for(int i = 0; i < iterations; i++){
    // place loop/unrolled loop here to do a bunch of multiply add ops
    // make sure you use results, so compiler does not optimize out
    result = result*val1 + val2;
     }
     g_odata[index] = result;
}

////////////////////////////////////////////////////////////////////////////////
// declaration, forward
void runTest( int argc, char** argv);

////////////////////////////////////////////////////////////////////////////////
// Program main
////////////////////////////////////////////////////////////////////////////////
int
main( int argc, char** argv)
{
    runTest( argc, argv);
}

////////////////////////////////////////////////////////////////////////////////
//! Run a simple test for CUDA
////////////////////////////////////////////////////////////////////////////////

//cuda utilization calculator 
void
runTest( int argc, char** argv)
{
    cudaEvent_t start, stop;
    cudaEventCreate(&start);
    cudaEventCreate(&stop);
    float *d_odata, *d_idata;
    
    // adjust number of threads here
    unsigned int num_threads_per_block = 1024;
    long int array_size = 20*(1<<20);
    unsigned int mem_size = sizeof( float) * array_size;
    
    // allocate host memory
    float* h_idata = (float*) malloc( mem_size);
    float* h_odata = (float*) malloc( mem_size);

    //allocate device memory
    CUDA_SAFE_CALL( cudaMalloc( (void**) &d_idata, mem_size));
    CUDA_SAFE_CALL( cudaMalloc( (void**) &d_odata, mem_size));

    // initalize the memory
    for(long int i = 0; i < array_size; ++i)
    {
        h_idata[i] = 1.0f;
        h_odata[i] = 2.0f;
    }

    // copy host memory to device
    CUDA_SAFE_CALL( cudaMemcpy( d_idata, h_idata, mem_size,cudaMemcpyHostToDevice) );
    CUDA_SAFE_CALL( cudaMemcpy( d_odata, h_odata, mem_size,cudaMemcpyHostToDevice) );
    
    // setup execution parameters
    // adjust thread block sizes here
    dim3  grid(ceil((array_size+num_threads_per_block-1)/num_threads_per_block), 1, 1);
    dim3  threads( num_threads_per_block, 1, 1);

    // execute the kernel
    cudaEventRecord(start, 0);
    testKernel<<< grid, threads>>>( d_idata, d_odata,array_size);
    cudaEventRecord(stop);
    cudaEventSynchronize(stop);

    // check if kernel execution generated and error
    // CUT_CHECK_ERROR("Kernel execution failed");

    // copy result from device to host
    CUDA_SAFE_CALL( cudaMemcpy( h_odata, d_odata, mem_size,cudaMemcpyDeviceToHost) );

    float elapsedTime;
    cudaEventElapsedTime(&elapsedTime, start, stop);
    printf( "Processing time: %f (ms)\n", elapsedTime);
    printf("Effective arithmetic throughput (GFLOP/s): %f \n", 2*array_size*iterations/elapsedTime/1e6);
    cudaEventDestroy(start);
    cudaEventDestroy(stop);

    // cleanup memory
    free( h_idata);
    free( h_odata);
    CUDA_SAFE_CALL(cudaFree(d_idata));
    CUDA_SAFE_CALL(cudaFree(d_odata));
}
